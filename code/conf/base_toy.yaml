inherit: 
    - models/GPT2.yaml
    - wandb.yaml

model:
    n_dims: 128
    n_positions: 512

training:
    data: gaussian
    task_kwargs: {}
    resume_id: /home/ismail/in-context-learning-main/src/models/gpt2_finetune/62158223-c246-4633-8ec6-3b021f89fbc2
    batch_size: 32
    learning_rate: 0.0001
    save_every_steps: 1000
    keep_every_steps: 100000
    train_steps: 500001
    curriculum:
        dims:
            start: 8
            end: 128
            inc: 2
            interval: 2000
